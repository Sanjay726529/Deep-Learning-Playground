{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Face and Eye recognition using opencv2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Detecting faces and various parts of the body has been the core idea Object detection which falls under computer vision technology. This involves detecting the face/parts in the video frame or captured images.**\n",
    "\n",
    "* We will use the cascade classifiers and Haar features to detect faces and eyes in the live video frames.\n",
    "* In Machine learning theses haar features are trained through tons of images with both containing target variable(face) and no target variable.\n",
    "* We will use a pre-trained face and eyes classifier to detect eyes/faces(targets) in the live video frame.\n",
    "\n",
    "[install opencv-python](https://pypi.org/project/opencv-python/#files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**face/eye detection classifier are provided as part of opencv-python package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "face_cascade_file = str(Path(cv2.__file__).parent / 'data' / 'haarcascade_frontalface_default.xml')\n",
    "faceclassifier = cv2.CascadeClassifier(face_cascade_file)\n",
    "\n",
    "eye_cascade_file = str(Path(cv2.__file__).parent / 'data' / 'haarcascade_eye.xml')\n",
    "eyeclassifier = cv2.CascadeClassifier(eye_cascade_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Following code open the front webcam of your PC and detects eyes/faces when in its frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to camera: True\n"
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0 + cv2.CAP_DSHOW)\n",
    "\n",
    "print(f\"Access to camera: {video_capture.isOpened()}\")\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # capture frames from video feed\n",
    "    cap_success, frame = video_capture.read()\n",
    "    \n",
    "    if not cap_success:\n",
    "        print(\"Failed to capture image through Camera\")\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    else:\n",
    "\n",
    "        # convert the captured data into grayscale color scheme\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # rgb_to_gray\n",
    "\n",
    "        # detect faces in the gray images\n",
    "        faces = faceclassifier.detectMultiScale(\n",
    "                                            gray, # image to be used\n",
    "                                            scaleFactor=1.1,\n",
    "                                            minNeighbors=5,\n",
    "                                            minSize=(30, 30),\n",
    "                                            flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        \n",
    "        # detect smiles in the gray images:\n",
    "        eyes = eyeclassifier.detectMultiScale(\n",
    "                                            gray, # image to be used\n",
    "                                            scaleFactor=1.1,\n",
    "                                            minNeighbors=5,\n",
    "                                            minSize=(30, 30),\n",
    "                                            flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        # bound the detected faces\n",
    "        for (x, y, width, height) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+width, y+height), (255, 255, 255), 2)\n",
    "        \n",
    "        # bound the detected smiles\n",
    "        for (x, y, width, height) in eyes:\n",
    "            cv2.rectangle(frame, (x, y), (x+width, y+height), (255, 255, 0), 2)\n",
    "\n",
    "        # display detected frame\n",
    "        cv2.imshow('Video', frame)\n",
    "    \n",
    "    if cv2.waitKey(113) == ord('q') or not video_capture.isOpened():\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Sample detection\n",
    "---\n",
    "\n",
    "![face_detect](face_detect.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv]",
   "language": "python",
   "name": "conda-env-cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# [Building Sobel vertical Edge detector from scratch](https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "1.1 Convert an image into array of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Input image\n",
    "\n",
    "![input](Valve_original.png) ![input](car-engine.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of first image is : (640, 480)\n",
      "The size of second image is : (640, 480)\n",
      "Array image shape: (3, 480, 640)\n",
      "Array image shape: (3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# read the image \n",
    "image1 = load_img(\"./Valve_original.png\")\n",
    "image2 = load_img(\"./car-engine.jpg\")\n",
    "\n",
    "print(\"The size of first image is :\", image1.size)\n",
    "print(\"The size of second image is :\", image2.size)\n",
    "\n",
    "# convert the image to array\n",
    "image1_arr = img_to_array(image1, data_format='channels_first')\n",
    "image2_arr = img_to_array(image2, data_format='channels_first')\n",
    "print(\"Array image shape:\", image1_arr.shape)\n",
    "print(\"Array image shape:\", image2_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "### Sobel Edge Detector Convolution\n",
    "\n",
    "* The read image is an color image, hence 480 pixels in height, 640px in height and 3 channels(RGB)\n",
    "* we will use the 3D sobel edge detector to detect the edges of the given image\n",
    "* kernel size = (3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# the values in the images range from 0(black) to 255(white)\n",
    "class convolution():\n",
    "    \n",
    "    def __init__(self, kernelh, kernelv):\n",
    "        # we will use horizontal kernel of size 3*3*3, and stride of 1, and no padding\n",
    "        self.kernelh = kernelh\n",
    "        self.kernelv = kernelv\n",
    "\n",
    "    def convolute(self, image, conv_type='both'):\n",
    "        ht = image.shape[1]\n",
    "        wd = image.shape[2]\n",
    "        # final image size will be (h-k+1)*(w-k+1)\n",
    "        convoluted_image = np.zeros((ht-3+1, wd-3+1))\n",
    "\n",
    "        for h in range(image.shape[1]-2): # height\n",
    "            for w in range(image.shape[2]-2):\n",
    "                if conv_type == 'vert':\n",
    "                    convoluted_image[h][w] = np.sum(self.kernelv * image[:, h:h+3, w:w+3])\n",
    "                elif conv_type == 'hori':\n",
    "                    convoluted_image[h][w] = np.sum(self.kernelh * image[:, h:h+3, w:w+3])\n",
    "                else:\n",
    "                    horizontal_c = np.sum(self.kernelh * image[:, h:h+3, w:w+3])\n",
    "                    vertical_c = np.sum(self.kernelv * image[:, h:h+3, w:w+3])\n",
    "                    convoluted_image[h][w] = np.sqrt(horizontal_c**2 + vertical_c**2)\n",
    "                    \n",
    "                \n",
    "        # rescale the convulated image using min_max to 0,255\n",
    "#         smin = 0\n",
    "#         smax = 255\n",
    "                \n",
    "#         convoluted_image = ((convoluted_image - np.min(convoluted_image)) * (smax - smin)) / (np.max(convoluted_image) - np.min(convoluted_image))\n",
    "        \n",
    "        return convoluted_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hkernel = np.array([[[-1, -2, -1],[0, 0, 0],[1, 2, 1]], [[-1, -2, -1],[0, 0, 0],[1, 2, 1]], [[-1, -2, -1],[0, 0, 0],[1, 2, 1]]])\n",
    "vkernel = np.array([[[-1, 0, 1],[-2, 0, 2],[-1, 0, 1]], [[-1, 0, 1],[-2, 0, 2],[-1, 0, 1]], [[-1, 0, 1],[-2, 0, 2],[-1, 0, 1]]])\n",
    "\n",
    "hconv = convolution(hkernel, vkernel)\n",
    "\n",
    "conv_image1 = hconv.convolute(image1_arr, conv_type='hori')\n",
    "conv_image2 = hconv.convolute(image2_arr, conv_type='hori')\n",
    "\n",
    "# save the image\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "conv_image1 = conv_image1.reshape((1, conv_image1.shape[0], conv_image1.shape[1]))\n",
    "conv_image2 = conv_image2.reshape((1, conv_image2.shape[0], conv_image2.shape[1]))\n",
    "after_image1 = array_to_img(conv_image1, data_format='channels_first', scale=True)\n",
    "after_image2 = array_to_img(conv_image2, data_format='channels_first', scale=True)\n",
    "after_image1.save(\"converted_image1_sobel_horizontal.png\")\n",
    "after_image2.save(\"converted_image2_sobel_horizontal.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### After horizontal convolution\n",
    "\n",
    "![after](converted_image1_sobel_horizontal.png)  ![after1](converted_image2_sobel_horizontal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Repeat the same with vertical sobel kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "vconv = convolution(hkernel, vkernel)\n",
    "\n",
    "conv_image1_v = vconv.convolute(image1_arr, conv_type='vert')\n",
    "conv_image2_v = vconv.convolute(image2_arr, conv_type='vert')\n",
    "\n",
    "# save the image\n",
    "conv_image1_v = conv_image1_v.reshape((1, conv_image1_v.shape[0], conv_image1_v.shape[1]))\n",
    "conv_image2_v = conv_image2_v.reshape((1, conv_image2_v.shape[0], conv_image2_v.shape[1]))\n",
    "after_image1_v = array_to_img(conv_image1_v, data_format='channels_first')\n",
    "after_image2_v = array_to_img(conv_image2_v, data_format='channels_first')\n",
    "after_image1_v.save(\"converted_image1_sobel_vertical.png\", rescale=True)\n",
    "after_image2_v.save(\"converted_image2_sobel_vertical.png\", rescale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### After verical convolution\n",
    "\n",
    "![after](converted_image1_sobel_vertical.png)  ![after2](converted_image2_sobel_vertical.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## mix of both kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "hvconv = convolution(hkernel, vkernel)\n",
    "\n",
    "conv_image1_hv = hvconv.convolute(image1_arr, conv_type='both')\n",
    "conv_image2_hv = hvconv.convolute(image2_arr, conv_type='both')\n",
    "\n",
    "# save the image\n",
    "conv_image1_hv = conv_image1_hv.reshape((1, conv_image1_hv.shape[0], conv_image1_hv.shape[1]))\n",
    "conv_image2_hv = conv_image2_hv.reshape((1, conv_image2_hv.shape[0], conv_image2_hv.shape[1]))\n",
    "after_image1_hv = array_to_img(conv_image1_hv, data_format='channels_first')\n",
    "after_image2_hv = array_to_img(conv_image2_hv, data_format='channels_first')\n",
    "after_image1_hv.save(\"converted_image1_sobel_hor_vert.png\", rescale=True)\n",
    "after_image2_hv.save(\"converted_image2_sobel_hor_vert.png\", rescale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### After mix of horizontal and verical convolution\n",
    "\n",
    "![after](converted_image1_sobel_hor_vert.png)    ![after2](converted_image2_sobel_hor_vert.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu]",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
